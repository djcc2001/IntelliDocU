filename,filename,arxiv_id,source_url,pages,language,file_type,notes
arxiv_251210942_vl_jepa.pdf,VL-JEPA: Joint Embedding Predictive Architecture for Vision-language,2512.10942,https://arxiv.org/abs/2512.10942,14,English,digital,Vision-Language Model; JEPA architecture; multimodal embeddings; selective decoding; VLM benchmark paper.
arxiv_251210954_group_diffusion.pdf,Group Diffusion: Enhancing Image Generation by Unlocking Cross-Sample Collaboration,2512.10954,https://arxiv.org/abs/2512.10954,21,English,digital,Diffusion models; joint denoising; cross-sample attention; Adobe Research + UCLA; 2025.
arxiv_251210953_bidirectional_normalizing_flow.pdf,Bidirectional Normalizing Flow: From Data to Noise and Back,2512.10953,https://arxiv.org/abs/2512.10953,18,English,digital,Normalizing Flows; BiFlow framework; MIT + Tsinghua; accelerates sampling; 2025.
arxiv_251210939_gaussianHeadTalk.pdf,GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio-Driven Gaussian Splatting,2512.10939,https://arxiv.org/abs/2512.10939,15,English,digital,Talking-head synthesis; audio-driven 3D Gaussian Splatting; temporal stability; transformer-based audio-to-FLAME prediction; University of Edinburgh + UCL (2025).
arxiv_251210938_stronger_normalization_free.pdf,Stronger Normalization-Free Transformers,2512.10938,https://arxiv.org/abs/2512.10938,22,English,digital,"Paper introducing Derf, a point-wise function that outperforms normalization (LayerNorm, RMSNorm, DyT) across vision, speech, DNA and language models."
arxiv_251210935_any4d.pdf,Any4D: Unified Feed-Forward Metric 4D Reconstruction,2512.10935,https://arxiv.org/abs/2512.10935,14,English,digital,"Multi-view transformer for dense metric 4D reconstruction; supports RGB, RGB-D, IMU, and Radar Doppler; produces geometry, scene flow, and camera poses; significantly faster (15Ã—) and more accurate than prior 4D models."
arxiv_251210932_babyvlm_v2.pdf,BabyVLM-V2: Toward Developmentally Grounded Pretraining and Benchmarking of Vision Foundation Models,2512.10932,https://arxiv.org/abs/2512.10932,27,English,digital,"Infant-centric multimodal pretraining; uses longitudinal audiovisual data; introduces DevCV Toolbox, a benchmark suite aligned with infant cognitive development; outperforming GPT-4o in some tasks."
arxiv_251210931_asynchronous_reasoning.pdf,Asynchronous Reasoning: Training-Free Interactive Thinking LLMs,2512.10931,https://arxiv.org/abs/2512.10931,16,English,digital,"Introduces a method to enable real-time asynchronous reasoning in LLMs using rotary embeddings; reduces time-to-first-token; evaluated on math, commonsense, and safety reasoning tasks."
arxiv_251210922_sparseswaps.pdf,SparseSwaps: Tractable LLM Pruning Mask Refinement at Scale,2512.10922,https://arxiv.org/abs/2512.10922,15,English,digital,Introduces a tractable 1-swap algorithm for layer-wise LLM pruning; avoids intractable integer programming; achieves up to 60% reduction in per-layer pruning error vs Wanda and improves perplexity/accuracy across GPT models.
arxiv_251210894_duetsvg.pdf,DuetSVG: Unified Multimodal SVG Generation with Internal Visual Guidance,2512.10894,https://arxiv.org/abs/2512.10894,14,English,digital,"SVG generation, multimodal model, image tokens + SVG tokens, unified architecture, benchmark results"